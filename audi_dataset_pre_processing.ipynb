{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import json\n",
    "import pickle\n",
    "import pptk\n",
    "from pyntcloud import PyntCloud\n",
    "import pptk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from A2D2 tutorial used for importing images\n",
    "def extract_image_file_name_from_lidar_file_name(file_name_lidar):\n",
    "    file_name_image = file_name_lidar.split('/')\n",
    "    file_name_image = file_name_image[-1].split('.')[0]\n",
    "    file_name_image = file_name_image.split('_')\n",
    "    file_name_image = file_name_image[0] + '_' + \\\n",
    "                        'camera_' + \\\n",
    "                        file_name_image[2] + '_' + \\\n",
    "                        file_name_image[3] + '.png'\n",
    "\n",
    "    return file_name_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary from hex --> RGB for classes\n",
    "def hex2rgb(hex_id):\n",
    "    hex_id = hex_id[1:]\n",
    "    return tuple(int(hex_id[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "def get_classes_to_ids(json_file=os.path.join(os.getcwd(), \"data\", \\\n",
    "                                              \"camera_lidar_semantic\", \"class_list.json\")):\n",
    "    with open(json_file) as file:\n",
    "        hex_dict = json.load(file)\n",
    "        file.close()\n",
    "\n",
    "    class_dict = {}\n",
    "    rgb_dict = {}\n",
    "    inverse_rgb_dict = {}\n",
    "\n",
    "    j = 0\n",
    "    for key in list(hex_dict.keys()):\n",
    "        class_dict[j] = hex_dict[key]\n",
    "        rgb_dict[hex2rgb(key)] = j\n",
    "        inverse_rgb_dict[j] = hex2rgb(key)\n",
    "        j += 1\n",
    "    \n",
    "    # Pickle these files once we're ready\n",
    "    dict_save = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary.pkl\")\n",
    "    with open(dict_save, \"wb\") as f:\n",
    "        pickle.dump([class_dict, rgb_dict], f)\n",
    "        f.close()\n",
    "    print(\"FILES PICKLED\")\n",
    "    return class_dict, rgb_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the RGB <--> Number Label <--> Class Label Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display PC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_point_cloud(tuple,seg_label=[],title=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    if seg_label == []:\n",
    "        x = [x[0] for x in tuple]\n",
    "        y = [y[1] for y in tuple]\n",
    "        z = [z[2] for z in tuple]\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        ax.scatter(x, y, z, c='b', cmap='spectral')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlabel('X')\n",
    "    else:\n",
    "        category = list(np.unique(seg_label))\n",
    "        color = ['b','r','g','y','w','b','p']\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        for categ_index in range(len(category)):\n",
    "            tuple_seg = tuple[seg_label == category[categ_index]]\n",
    "            x = [x[0] for x in tuple_seg]\n",
    "            y = [y[1] for y in tuple_seg]\n",
    "            z = [z[2] for z in tuple_seg]\n",
    "            ax.scatter(x, y, z, c=color[categ_index], cmap='spectral')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlabel('X')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading and merging data\n",
    "def merge_data(start_index=None, stop_index=None, combine_classes=False):\n",
    "    # Get current working directory and data folder\n",
    "    CWD = os.getcwd()\n",
    "    data_folder = os.path.join(CWD, \"data\",\"camera_lidar_semantic\")\n",
    "    \n",
    "\n",
    "    # Get classes <--> labels dictionaries\n",
    "    class_dict, rgb_dict = get_classes_to_ids()\n",
    "    \n",
    "    if combine_classes:\n",
    "        combined_classes = {'road': [32, 40, 44, 42, 50, 27, 40, 42, 44, 50], \\\n",
    "                            'car': [0, 1, 2, 3, 11, 12, 13, 14, 15, 16, 23, 24, 46], \\\n",
    "                            'pedestrian': [4, 5, 6, 7, 8, 9, 10], \\\n",
    "                            'road signs/signals': [17, 18, 19, 20, 21, 22], \\\n",
    "                            'lanes': [28, 47, 48, 49]}\n",
    "    \n",
    "    # Get folders which we will recursively scrape from to aggregate data\n",
    "    sub_folders = os.listdir(data_folder)\n",
    "    sub_folders_all_dir = [sub_folder for sub_folder in sub_folders if \\\n",
    "                    os.path.isdir(os.path.join(data_folder,sub_folder))]\n",
    "    sub_folders_filtered = [sub_folder for sub_folder in sub_folders_all_dir if \\\n",
    "              \"lidar\" in os.listdir(os.path.join(data_folder,sub_folder)) and\n",
    "              \"label\" in os.listdir(os.path.join(data_folder,sub_folder)) and\n",
    "              \"camera\" in os.listdir(os.path.join(data_folder,sub_folder))]\n",
    "\n",
    "    # Get IDs for iterating through each (image, label, point cloud) triple\n",
    "    IDs = set()\n",
    "    for sub_folder in sub_folders_filtered:\n",
    "        sub_data_dir = os.path.join(data_folder, sub_folder,\"camera\",\"cam_front_center\")\n",
    "        files = os.listdir(sub_data_dir)\n",
    "        file_IDs = [file.split(\"_\")[0]+\"_\"+file.split(\"_\")[-1].split(\".\")[0] for file in files]\n",
    "        IDs.update(file_IDs)\n",
    "\n",
    "    print(\"Number of IDs in dataset: {}\".format(len(list(IDs))))\n",
    "\n",
    "\n",
    "    Dataset = {}\n",
    "    i = 0\n",
    "    \n",
    "    if start_index is None:\n",
    "        start_index = 0\n",
    "    if stop_index is None:\n",
    "        stop_index = len(IDs)\n",
    "    print(\"START index is {}, STOP index is {}\".format(start_index, stop_index))\n",
    "    # Iterate over point clouds, rgb, and labels\n",
    "    for ID in list(IDs)[start_index:stop_index]:\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Iterated through {} files\".format(i))\n",
    "        # Get ID information\n",
    "        ID_split = ID.split(\"_\")\n",
    "        ID_split[-1] = ID_split[-1].split(\".\")[0]\n",
    "        \n",
    "        # Get directories for each individual set of images, labels, and point clouds\n",
    "        ind_data_dir = os.path.join(data_folder, ID_split[0][:-6]+\"_\"+ID_split[0][-6:])\n",
    "        ind_pc_dir = os.path.join(ind_data_dir, \"lidar\", \"cam_front_center\")\n",
    "        ind_label_dir = os.path.join(ind_data_dir, \"label\", \"cam_front_center\")\n",
    "        ind_camera_dir = os.path.join(ind_data_dir, \"camera\", \"cam_front_center\")\n",
    "        \n",
    "        # Get filenames for images, labels, and point clouds\n",
    "        pc_file_name =  ID_split[0]+\"_lidar_frontcenter_\"+ID_split[1]+\".npz\"\n",
    "        label_file_name = ID_split[0]+\"_label_frontcenter_\"+ID_split[1]+\".png\"\n",
    "        camera_file_name = ID_split[0]+\"_camera_frontcenter_\"+ID_split[1]+\".png\"\n",
    "        \n",
    "        # Load images, labels, and point clouds\n",
    "        A_label = cv.imread(os.path.join(ind_label_dir, label_file_name))\n",
    "        A_camera = cv.imread(os.path.join(ind_camera_dir, camera_file_name))\n",
    "        pc = np.load(os.path.join(ind_pc_dir,pc_file_name), allow_pickle=True)\n",
    "        \n",
    "        # Give labels to points in PC equal to [row, index] these points map to in label image space\n",
    "        keys = list(pc.keys())\n",
    "        if 'row' in keys and 'col' in keys and 'points' in keys:\n",
    "            rows, cols = pc['row'], pc['col']\n",
    "            classes = []\n",
    "            rgb = []\n",
    "            N = len(rows)\n",
    "            for row, col in zip(rows, cols): # O(n)\n",
    "                rgb_data = A_camera[int(row), int(col), :][::-1]\n",
    "                rgb_label = tuple(A_label[int(row), int(col), :])[::-1]\n",
    "                \n",
    "                # 6 different classes\n",
    "                if combine_classes==\"six_classes\":\n",
    "                    if rgb_dict[rgb_label] in combined_classes['road']:\n",
    "                        classes.append(1)\n",
    "                    elif rgb_dict[rgb_label] in combined_classes['car']:\n",
    "                        classes.append(2)\n",
    "                    elif rgb_dict[rgb_label] in combined_classes['pedestrian']:\n",
    "                        classes.append(3)\n",
    "                    elif rgb_dict[rgb_label] in combined_classes['road signs/signals']:\n",
    "                        classes.append(4)\n",
    "                    elif rgb_dict[rgb_label] in combined_classes['lanes']:\n",
    "                        classes.append(5)\n",
    "                    else:\n",
    "                        classes.append(0)\n",
    "                \n",
    "                # MVP - Road Detector\n",
    "                elif combine_classes==\"road_detection\":\n",
    "                    if rgb_dict[rgb_label] in combined_classes['road']:\n",
    "                        classes.append(1)\n",
    "                    else:\n",
    "                        classes.append(0)\n",
    "                \n",
    "                # Create labels over all 55 classes\n",
    "                else:  \n",
    "                    classes.append(rgb_dict[rgb_label]) # O(1)\n",
    "                rgb.append(rgb_data)\n",
    "            classes = np.array(classes)\n",
    "            rgb = np.array(rgb).reshape((N, 3))\n",
    "            Dataset[ID] = {'points': pc['points'], 'labels': classes, 'rgb': rgb}\n",
    "        i += 1\n",
    "        pickle_outfile = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera_{}_ids.pkl\".format(i))\n",
    "    if combined_classes == \"six_classes\":\n",
    "        pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                            \"dataset_pc_labels_camera_start_{}_stop_{}_COMBINED_CLASSES.pkl\".format(start_index, \\\n",
    "                                                                                                    stop_index))\n",
    "    elif combined_classes == \"road_detection\":\n",
    "        pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                            \"dataset_pc_labels_camera_start_{}_stop_{}_ROAD_DETECTION.pkl\".format(start_index, \\\n",
    "                                                                                                    stop_index))\n",
    "    else:\n",
    "         pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                            \"dataset_pc_labels_camera_start_{}_stop_{}.pkl\".format(start_index, stop_index))\n",
    "    with open(pickle_outfile, \"wb\") as f:\n",
    "        pickle.dump(Dataset, f)\n",
    "        f.close()\n",
    "    return Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rgb_id_consistency(Dataset):\n",
    "    dataset_pickle = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera.pkl\")\n",
    "    with open(dataset_pickle, \"wb\") as f:\n",
    "        pickle.dump(Dataset, f)\n",
    "        f.close()\n",
    "\n",
    "    with open(dataset_pickle,\"rb\") as f:\n",
    "        D = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    keys = list(D.keys())[:len(keys)]\n",
    "    minidataset = {key: D[key] for key in keys}\n",
    "    for key in keys:\n",
    "        A_img = D[key]['rgb']\n",
    "        A_label = D[key]['rgb_labels']\n",
    "        print(A_img.shape, A_label.shape)\n",
    "        plt.imshow(A_img)\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        plt.imshow(A_label)\n",
    "        plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_id_consistency(D, index):\n",
    "    # Define and get IDs\n",
    "    ID = list(D.keys())[index]\n",
    "    labels_pc = D[ID][\"labels\"]\n",
    "    \n",
    "    # Current working directory and data directory\n",
    "    CWD = os.getcwd()\n",
    "    data_folder = os.path.join(CWD, \"data\",\"camera_lidar_semantic\")\n",
    "\n",
    "    # Get classes <--> labels dictionaries\n",
    "    class_dict, rgb_dict = get_classes_to_ids()\n",
    "    inverse_rgb_dict = {rgb_dict[key]:key for key in list(rgb_dict.keys())}\n",
    "    \n",
    "    # Split ID string for parsing below\n",
    "    ID_split = ID.split(\"_\")\n",
    "    ID_split[-1] = ID_split[-1].split(\".\")[0]\n",
    "    print(\"ID is: {}, ID_split is: {}\".format(ID, ID_split))\n",
    "    \n",
    "    # Get paths for image, labels, and point clouds\n",
    "    ind_data_dir = os.path.join(data_folder, ID_split[0][:-6]+\"_\"+ID_split[0][-6:])\n",
    "    ind_pc_dir = os.path.join(ind_data_dir, \"lidar\", \"cam_front_center\")\n",
    "    ind_label_dir = os.path.join(ind_data_dir, \"label\", \"cam_front_center\")\n",
    "    ind_camera_dir = os.path.join(ind_data_dir, \"camera\", \"cam_front_center\")\n",
    "\n",
    "    # Get file names for image, labels, and point clouds\n",
    "    pc_file_name =  ID_split[0]+\"_lidar_frontcenter_\"+ID_split[1]+\".npz\"\n",
    "    label_file_name = ID_split[0]+\"_label_frontcenter_\"+ID_split[1]+\".png\"\n",
    "    camera_file_name = ID_split[0]+\"_camera_frontcenter_\"+ID_split[1]+\".png\"\n",
    "\n",
    "    # Load data for image, labels, and point clouds\n",
    "    A_label = cv.imread(os.path.join(ind_label_dir, label_file_name))\n",
    "    pc = np.load(os.path.join(ind_pc_dir,pc_file_name), allow_pickle=True)\n",
    "    print(pc)\n",
    "    A_camera = cv.imread(os.path.join(ind_camera_dir, camera_file_name))\n",
    "    \n",
    "    keys = list(pc.keys())\n",
    "    ID_split = ID.split(\"_\")\n",
    "    ID_split[-1] = ID_split[-1].split(\".\")[0]\n",
    "    \n",
    "    # Give labels to points in PC equal to [row, index] these points map to in label image space \n",
    "    label_file_name = ID_split[0]+\"_label_frontcenter_\"+ID_split[1]+\".png\"\n",
    "    Img = os.path.join(ind_label_dir, label_file_name)\n",
    "    rows, cols = pc['row'], pc['col']\n",
    "    classes = []\n",
    "    rgb_labels = []\n",
    "    test_img = A_camera\n",
    "    for row, col, label in zip(rows, cols, labels_pc): # O(n)\n",
    "        rgb_data = A_camera[int(row), int(col), :][::-1]\n",
    "        rgb_label = tuple(A_label[int(row), int(col), :])[::-1]\n",
    "        classes.append(rgb_dict[rgb_label]) # O(1)\n",
    "        rgb_labels.append(rgb_label)\n",
    "        #test_img[int(row),int(col),:] = np.array(inverse_rgb_dict[label])\n",
    "        test_img[int(row),int(col),:] = rgb_data\n",
    "    print(\"TEST if zero (zero indicates correct behavior): {}\".format(\\\n",
    "                                np.sum(np.subtract(labels_pc, np.array(classes)))))\n",
    "    \n",
    "    # Display the point cloud\n",
    "    show_point_cloud(pc['points'],seg_label=classes)\n",
    "    \n",
    "    # Plot to qualitatively confirm results\n",
    "    plt.imshow(A_camera)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.imshow(A_label)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all GT semantic images, and find all unique RGB triplets for class values.\n",
    "def make_semantic_mask_dict(seg_img_dir):\n",
    "    imgs = os.listdir(seg_img_dir)\n",
    "    color_triplets = set()\n",
    "    for img in imgs:\n",
    "        A_label = cv.imread(img)\n",
    "        img_triplets = np.unique(img.reshape(-1, img.shape[2]), axis=0)\n",
    "        color_triplets.update(img_triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for pickling files\n",
    "def pickle_file(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "        f.close()\n",
    "    print(\"Object pickled to file located at {}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading pickle files\n",
    "def load_pickle_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "        f.close()\n",
    "    print(\"Object loaded from file located at {}\".format(path))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's create a function for merging all of this data, and pickle this file to be saved\n",
    "def create_and_export_data(start_indices = [i*2000 for i in range(0, 14)], \\\n",
    "                           stop_indices = [i*2000 for i in range(1, 15)]):\n",
    "    for start, stop in zip(start_indices, stop_indices):\n",
    "        Dataset = merge_data(start_index=start, stop_index=stop)\n",
    "        print(\"Processed indices from {} to {}\".format(start, stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Now load dummy dataset\n",
    "    pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                                      \"dataset_pc_labels_camera_start_{}_stop_{}.pkl\".format(0, 3))\n",
    "\n",
    "    with open(pickle_outfile, \"rb\") as f:\n",
    "        A = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    keys = list(A.keys())\n",
    "    for key in keys:\n",
    "        CWD = os.getcwd()\n",
    "        data_folder = os.path.join(CWD, \"data\",\"camera_lidar_semantic\")\n",
    "        ID_split = key.split(\"_\")\n",
    "        ID_split[-1] = ID_split[-1].split(\".\")[0]\n",
    "\n",
    "        # Get paths for image, labels, and point clouds\n",
    "        ind_data_dir = os.path.join(data_folder, ID_split[0][:-6]+\"_\"+ID_split[0][-6:])\n",
    "        RGB = A[key]['rgb']\n",
    "        ind_camera_dir = os.path.join(ind_data_dir, \"camera\", \"cam_front_center\")\n",
    "        ind_pc_dir = os.path.join(ind_data_dir, \"lidar\", \"cam_front_center\")\n",
    "\n",
    "\n",
    "        pc_file_name =  ID_split[0]+\"_lidar_frontcenter_\"+ID_split[1]+\".npz\"\n",
    "        label_file_name = ID_split[0]+\"_label_frontcenter_\"+ID_split[1]+\".png\"\n",
    "        camera_file_name = ID_split[0]+\"_camera_frontcenter_\"+ID_split[1]+\".png\"\n",
    "\n",
    "        A_camera = cv.imread(os.path.join(ind_camera_dir, camera_file_name))\n",
    "        pc = np.load(os.path.join(ind_pc_dir,pc_file_name), allow_pickle=True)\n",
    "\n",
    "        # Give labels to points in PC equal to [row, index] these points map to in label image space\n",
    "        keys = list(pc.keys())\n",
    "        if 'row' in keys and 'col' in keys and 'points' in keys:\n",
    "            rows, cols = pc['row'], pc['col']\n",
    "            classes = []\n",
    "            rgb = []\n",
    "            N = len(rows)\n",
    "            i = 0\n",
    "            for row, col in zip(rows, cols): # O(n)\n",
    "                i += 1\n",
    "\n",
    "\n",
    "    # Get classes <--> labels dictionaries\n",
    "    class_dict, rgb_dict = get_classes_to_ids()\n",
    "    inverse_rgb_dict = {rgb_dict[key]:key for key in list(rgb_dict.keys())}\n",
    "\n",
    "    test_id_consistency(A,1)\n",
    "    # Now load dummy dataset\n",
    "    pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                                      \"dataset_pc_labels_camera_start_{}_stop_{}.pkl\".format(0, 3))\n",
    "\n",
    "    with open(pickle_outfile, \"rb\") as f:\n",
    "        A = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    keys = list(A.keys())\n",
    "    for key in keys:\n",
    "        print(A[key]['rgb'].shape)\n",
    "        print(A[key]['labels'].shape)\n",
    "        print(A[key]['points'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset for Road Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Dataset To Ensure Proper Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "pkl_file = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera_start_0_stop_10000_ROAD_DETECTION.pkl\")\n",
    "                        \n",
    "with open(pkl_file, \"rb\") as f:\n",
    "    D = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "key = list(D.keys())[0]\n",
    "print(np.max(D[key]['labels']))\n",
    "print(np.min(D[key]['labels']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "pkl_file = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera_start_0_stop_10000_COMBINED_CLASSES.pkl\")\n",
    "with open(pkl_file, \"rb\") as f:\n",
    "    D = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "keys = list(D.keys())\n",
    "\n",
    "# Now change the labels for each stage\n",
    "\n",
    "# Stage 1\n",
    "labels_map_stage_1 = {0: 0, 1: 0, 2: 0, 3: 3, 4: 0, 5: 0} \n",
    "labels_stage_1 = {} \n",
    "for key in keys:\n",
    "    labels_stage_1[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_1[key].append(labels_map_stage_1[label])\n",
    "pkl_out_file_stage_1 = os.path.join(os.getcwd(), \"data\", \"stage_1_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_1, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_1, f)\n",
    "    f.close()\n",
    "    \n",
    "# Stage 2\n",
    "labels_map_stage_2 = {0: 0, 1: 0, 2: 0, 3: 3, 4: 4, 5: 0}\n",
    "labels_stage_2 = {} \n",
    "for key in keys:\n",
    "    labels_stage_2[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_2[key].append(labels_map_stage_2[label])\n",
    "pkl_out_file_stage_2 = os.path.join(os.getcwd(), \"data\", \"stage_2_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_2, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_2, f)\n",
    "    f.close()\n",
    "    \n",
    "# Stage 3\n",
    "labels_map_stage_3 = {0: 0, 1: 0, 2: 0, 3: 3, 4: 4, 5: 5}\n",
    "labels_stage_3 = {} \n",
    "for key in keys:\n",
    "    labels_stage_3[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_3[key].append(labels_map_stage_3[label])\n",
    "pkl_out_file_stage_3 = os.path.join(os.getcwd(), \"data\", \"stage_3_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_3, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_3, f)\n",
    "    f.close()\n",
    "\n",
    "# Stage 4\n",
    "labels_map_stage_4 = {0: 0, 1: 0, 2: 2, 3: 3, 4: 4, 5: 5}\n",
    "labels_stage_4 = {} \n",
    "for key in keys:\n",
    "    labels_stage_4[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_4[key].append(labels_map_stage_4[label])\n",
    "pkl_out_file_stage_4 = os.path.join(os.getcwd(), \"data\", \"stage_4_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_4, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_4, f)\n",
    "    f.close()\n",
    "    \n",
    "# Stage 5\n",
    "labels_map_stage_5 = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
    "labels_stage_5 = {} \n",
    "for key in keys:\n",
    "    labels_stage_5[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_5[key].append(labels_map_stage_5[label])\n",
    "pkl_out_file_stage_5 = os.path.join(os.getcwd(), \"data\", \"stage_5_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_5, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_5, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Different-Staged Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating .pkl files for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/869_final_project/point-cloud-transfer-learning/data/camera_lidar_semantic/class_dictionary_COMBINED.pkl\n"
     ]
    }
   ],
   "source": [
    "classes_combined = {0:\"other\", 1:\"road\", 2:\"car\", 3:\"pedestrian\", 4:\"road signs/signals\", 5:\"lanes\"}\n",
    "pkl_out_file = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_COMBINED.pkl\")\n",
    "print(pkl_out_file)\n",
    "with open(pkl_out_file, \"wb\") as f:\n",
    "    pickle.dump(classes_combined, f)\n",
    "    f.close()\n",
    "    \n",
    "classes_road_detection = {0:\"non-road\", 1:\"road\"}\n",
    "pkl_out_file_road = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_ROAD_DETECTION.pkl\")\n",
    "with open(pkl_out_file_road, \"wb\") as f:\n",
    "    pickle.dump(classes_road_detection, f)\n",
    "    f.close()\n",
    "\n",
    "# Write for Stage 1\n",
    "classes_stage_1 = {0:\"other\", 3:\"pedestrian\"}\n",
    "pkl_out_file_stage_1 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_1.pkl\")\n",
    "with open(pkl_out_file_stage_1, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_1, f)\n",
    "    f.close()\n",
    "\n",
    "# Write for Stage 2\n",
    "classes_stage_2 = {0:\"other\", 3:\"pedestrian\", 4:\"road signs/signals\"}\n",
    "pkl_out_file_stage_2 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_2.pkl\")\n",
    "with open(pkl_out_file_stage_2, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_2, f)\n",
    "    f.close()\n",
    "\n",
    "# Write for Stage 3\n",
    "classes_stage_3 = {0:\"other\", 3:\"pedestrian\", 4:\"road signs/signals\", 5:\"lanes\"}\n",
    "pkl_out_file_stage_3 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_3.pkl\")\n",
    "with open(pkl_out_file_stage_3, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_3, f)\n",
    "    f.close()\n",
    "    \n",
    "# Write for Stage 4\n",
    "classes_stage_4 = {0:\"other\", 3:\"pedestrian\", 4:\"road signs/signals\", 5:\"lanes\", 2:\"car\"}\n",
    "pkl_out_file_stage_4 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_4.pkl\")\n",
    "with open(pkl_out_file_stage_4, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_4, f)\n",
    "    f.close()\n",
    "    \n",
    "# Write for Stage 5\n",
    "classes_stage_5 = {0:\"other\", 3:\"pedestrian\", 4:\"road signs/signals\", 5:\"lanes\", 2:\"car\", 1:\"road\"}\n",
    "pkl_out_file_stage_5 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_5.pkl\")\n",
    "with open(pkl_out_file_stage_5, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_5, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_point_cloud(tuple,seg_label=[],title=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    if seg_label == []:\n",
    "        x = [x[0] for x in tuple]\n",
    "        y = [y[1] for y in tuple]\n",
    "        z = [z[2] for z in tuple]\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        ax.scatter(x, y, z, c='b', cmap='spectral')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlabel('X')\n",
    "    else:\n",
    "        category = list(np.unique(seg_label))\n",
    "        color = ['b','r','g','y','w','b','p']\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        for categ_index in range(len(category)):\n",
    "            tuple_seg = tuple[seg_label == category[categ_index]]\n",
    "            x = [x[0] for x in tuple_seg]\n",
    "            y = [y[1] for y in tuple_seg]\n",
    "            z = [z[2] for z in tuple_seg]\n",
    "            ax.scatter(x, y, z, c=color[categ_index], cmap='spectral')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlabel('X')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL",
   "language": "python",
   "name": "drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
